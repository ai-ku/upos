\section{POS Induction for Word Tokens}
\label{sec:tokens}

In this section, we extend the random-substitutes algorithm presented
earlier to perform POS induction for the word tokens rather the than
word types.  We use the same settings in the Section~\ref{sec:wordsub}
and generate word ($X$) -- random-substitute ($Y$) pairs as the input
to the S-CODE.  For each observed $X$ -- $Y$ pair in the S-CODE input,
corresponding 25-dimensional $\phi_x$ and $\psi_y$ embedding vectors
are concatenated to create a 50-dimensional representation.  The
resulting 50-dimensional vectors are clustered using the instance
weighted k-means algorithm (with fewer restarts to accommodate the
input size).  The process yields 64 cluster-ids (for every pair
generated from word token's context) for each word token's context.
The word tokens' cluster-ids are predicted by the majority cluster-id
of the corresponding pairs.  Ties for the majority are broken
randomly.  The many-to-one accuracy is \wsxymto\ and the V-measure is
\wsxyvm\ .

In order to demonstrate the merit in the token based POS induction, we
first define the gold-tag perplexity for the word types as following:
\begin{equation} \label{eq:tag-perp}
GP(w) = 2^{H(p_w)} = 2^{-\sum_{x} p_w(x)log_2 p_w(x)}
\end{equation}
Where $p_w$ is the gold POS tag distribution of the word type $w$ and
$H(p_w)$ is the entropy of the $p_w$ distribution.
\begin{table}[t] \footnotesize
\caption{Accuracy in the gold-tag perplexity separated subsets.}
\begin{tabular}{|@{ }l@{ }|@{ }l@{ }|@{ }l@{ }|}
\hline
Model & \specialcell{$GP < 1.75$\\$89\%$} & \specialcell{$GP \ge 1.75$\\$11\%$}\\
\hline
Substitutes(Type) & .8054 (.0065) & .4383 (.0104)\\
\hline
Substitutes(Tokens) & .7322 (.0079) & .4671 (.0174)\\
\hline
\end{tabular}
\label{tab:bins}
\end{table}
Gold-tag perplexity ($GP$) is used to determine the POS ambiguity of
the word types, relating how often a word type is associated with
different POS tags in the test corpus.  A $GP$ of 1 for a word type
$w$ indicates $w$ is associated with same POS tag throughout the test
corpus, meaning the word type $w$'s POS is unambiguous.  As the $GP$
increases ambiguity for the word types increases and poses a handicap
for induction models that limits tag variety for the word types.  To
display the limitations, we split the test corpus in two subsets: word
types with $GP$ less than 1.75 and word types with $GP$ equal or greater
than 1.75.  We performed \mto\ evaluation on the the whole test corpus
induction output and obtained the induced-tag -- gold-tag
mappings. Using the mappings obtained over the test corpus, we
evaluated the accuracy in the subsets.  Table~\ref{tab:bins} presents
the evaluation over the subsets.
