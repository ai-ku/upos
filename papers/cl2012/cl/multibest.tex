\section{Multiple Languages}
\input{multitable.tex} 

Following Christodoulopoulos et
al. \shortcite{christodoulopoulos-goldwater-steedman:2011:EMNLP} we
continue to evaluate our model on the languages of MULTEXT-East
\cite{citeulike:5820223} multilingual corpora and the
CoNLL-X \cite{Buchholz:2006:CST:1596276.1596305} shared task.  The test
set consists of 8 languages from Multext-East(Bulgarian, Czech,
English, Estonian, Hungarian, Romanian, Slovene and Serbian) and 10
languages from the CoNLL-X shared task(Bulgarian, Czech, Danish, Duch,
German, Portuguese, Slovene, Spanish, Swedish and Turkish).  During
testing we only use the training section of each language data sets
\cite{Lee:2010:STU:1870658.1870741}.[parameter setting?? dont say
  development]

Languages of Multext-East corpora do not tag the punctuation marks,
thus we add an extra tag for punctuation to the tagset of these
languages.  The number of word types and clusters of each language are
summarized in Table~\ref{tab:multiresults}.

\subsection{Substitute Vectors}
To calculate substitute probabilities, we trained language models
using the Wikipedia dump files of the target languages\footnote{See
  Appendix~\ref{app:lm}for further details.}  as it is detailed in
Section~\ref{sec:lm}.  The word count of Wikipedia dump files vary
across the languages, in order to reduce the unknow word ratio of
resource poor languages and standartize the process we set the unknown
word threshold to 2 for all languages.  As a result we only replaced
the words that are observed less than 2 times in the language model
training data(language model statistics are detailed in
Appendix~\ref{app-datax}).

\subsection{Features}
We use the same set of ortographic features described in
Section~\ref{sec:feat} except we add an extra ``Only-Punctuation''
feature to the languages of MULTEXT-EAST corpora.  The
``Only-Punctuaion'' is generated when a token contains only
punctuations.  

Morphological features of each language is extracted by the method
described in Section~\ref{sec:feat}.  The number of suffix types are
summarized in Appendix~\ref{morpho}.

\subsection{Results}

We perform experiments with a range of languages and three different
feature setups to establish both the robustness of our model across
languages and to observe the effects of different features.  For each
language we report results: (1) without features(uPos), (2) with
ortographic features(uPos+O) and (3) with ortographic and
morphological features together(uPos+O+M).  In accord with our
development set, we use the best performing setup of
Section~\ref{sec:exp}\footnote{In Section~\ref{sec:wordsub} the best
  result is achieved on a 25 dimensional sphere with 64 substitutes.}.
As a baseline model we chose the bigram version of S-Code described in
Section~\ref{sec:bigram} which is a very strong baseline compared to
the ones used in \cite{christodoulopoulos-goldwater-steedman:2011:EMNLP}
Table~\ref{tab:multiresults} summarizes the \mto and \vm scores of the
bigram model and our models together with the best published score on
each language.

uPos significantly outperformed the bigram baseline in both \mto and
\vm scores on 14 languages while bigram model performed better on
Romanian and Serbian.  uPos+O and uPos+O+M achieved the highest \mto
scores on all languages of MULTEXT-EAST corpora however they scored
the highest \vm scores only on English and Romanian.  On the CoNLL-X
languages Pos+O and uPos+M models perform better than the best
published \mto score on 7 languages (Czech, Dutch, German, Portuguese,
Slovene, Swedish and Turkish).  Similarly, both models achieved the
top \vm scores on 7 languages (Czech, Danish, Dutch, German,
Portuguese, Spanish and Turkish).  uPos achieves a best \mto score on
Bulgarian.

