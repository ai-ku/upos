\section{Substitute Vectors}
\label{sec:lm}

In this study, we predict the part of speech of a word in a given
context based on its substitute vector.  The dimensions of the
substitute vector represent words in the vocabulary, and the entries
in the substitute vector represent the probability of those words
being used in the given context.  Note that the substitute vector is a
function of the context only and is indifferent to the target word.
This section details the choice of the data set, the vocabulary and
the estimation of substitute vector probabilities.

% what is the test data
The Wall Street Journal Section of the Penn Treebank \cite{treebank3}
was used as the test corpus (1,173,766 tokens, 49,206 types).
% what is the tag set
The treebank uses 45 part-of-speech tags which is the set we used as
the gold standard for comparison in our experiments.
% what is the LM training data
%Train => 5181717 126019973 690121813
To compute substitute probabilities we trained a language model using
approximately 126 million tokens of Wall Street Journal data
(1987-1994) extracted from CSR-III Text \cite{csr3text} (we excluded
the test corpus).
% how is the language model trained
We used SRILM \cite{Stolcke2002} to build a 4-gram language model with
Kneser-Ney discounting.
% what is the vocabulary
Words that were observed less than 20 times in the language model
training data were replaced by \textsc{unk} tags, which gave us a
vocabulary size of 78,498.
% perplexity
The perplexity of the 4-gram language model on the test corpus is 96.

% how are the substitutes computed
It is best to use both left and right context when estimating the
probabilities for potential lexical substitutes.  For example, in
\emph{``He lived in San Francisco suburbs.''}, the token \emph{San}
would be difficult to guess from the left context but it is almost
certain looking at the right context.  We define $c_w$ as the $2n-1$
word window centered around the target word position: $w_{-n+1} \ldots
w_0 \ldots w_{n-1}$ ($n=4$ is the n-gram order).  The probability of a
substitute word $w$ in a given context $c_w$ can be estimated as:
\begin{eqnarray}
  \label{eq:lm1}P(w_0 = w | c_w) & \propto & P(w_{-n+1}\ldots w_0\ldots w_{n-1})\\
  \label{eq:lm2}& = & P(w_{-n+1})P(w_{-n+2}|w_{-n+1})\nonumber\\
  &&\ldots P(w_{n-1}|w_{-n+1}^{n-2})\\
  \label{eq:lm3}& \approx & P(w_0| w_{-n+1}^{-1})P(w_{1}|w_{-n+2}^0)\nonumber\\
  &&\ldots P(w_{n-1}|w_0^{n-2})
\end{eqnarray}
where $w_i^j$ represents the sequence of words $w_i w_{i+1} \ldots
w_{j}$.  In Equation \ref{eq:lm1}, $P(w|c_w)$ is proportional to
$P(w_{-n+1}\ldots w_0 \ldots w_{n+1})$ because the words of the
context are fixed.  Terms without $w_0$ are identical for each
substitute in Equation \ref{eq:lm2} therefore they have been dropped
in Equation \ref{eq:lm3}.  Finally, because of the Markov property of
n-gram language model, only the closest $n-1$ words are used in the
experiments.

Near the sentence boundaries the appropriate terms were truncated in
Equation \ref{eq:lm3}.  Specifically, at the beginning of the sentence
shorter n-gram contexts were used and at the end of the sentence terms
beyond the end-of-sentence token were dropped.

For computational efficiency only the top 100 substitutes and their
unnormalized probabilities were computed for each of the 1,173,766
positions in the test set\footnote{The substitutes with unnormalized
  log probabilities can be downloaded from \mbox{\url{http://goo.gl/jzKH0}}.
  For a description of the {\sc fastsubs} algorithm used to generate
  the substitutes please see \mbox{\url{http://arxiv.org/abs/1205.5407v1}}.
  {\sc fastsubs} accomplishes this task in about 5 hours, a naive
  algorithm that looks at the whole vocabulary would take more than 6
  days on a typical 2012 workstation.}.  The probability vectors for
each position were normalized to add up to 1.0 giving us the final
substitute vectors used in the rest of this study.

% I guess we can use this part from acl12

% example substitute vectors (both syntactic and semantic)
The high probability substitutes reflect both semantic and syntactic
features of the context as seen in the examples given in
Table~\ref{tab:subs}.  Top substitutes for the word ``the'' consist of
words that can act as determiners.  Top substitutes for ``board'' are
not only nouns, but specifically nouns compatible with the semantic
context.

% we should update the probabilities here

\begin{table}[h]\centering
\begin{tabular}{|l|ll|} \hline
% \multicolumn{3}{|l|}
\emph{word} & \emph{substitute} & \emph{probability} \\ \hline
the	& its & .9011 \\
	& the & .0978 \\
	& a & .0007 \\ \hline
board	& company & .5573 \\
	& firm & .2219 \\
	& bank & .0727 \\ \hline
\end{tabular}
\caption{Example substitutes for ``the'' and ``board'' in the sentence {\em ``Pierre Vinken, 61 years old, will join the  board as a nonexecutive director Nov. 29.''}}
\label{tab:subs}
\end{table}


These examples illustrate two concerns inherent in all distributional
methods: (i) words that are generally substitutable like ``the'' and
``its'' are placed in separate categories ({\sc dt} and {\sc prp\$})
by the gold standard, (ii) words that are generally not substitutable
like ``board'' and ``banana'' are placed in the same category ({\sc
  nn}).  
% maybe we can add extrinsic evaluation ??
Whether gold standard part-of-speech tags or distributional categories
are better suited to applications like parsing or machine translation
can be best decided using extrinsic evaluation.  However in this study
we follow most previous work and evaluate our results by comparing
them to gold standard part-of-speech tags.

%%
