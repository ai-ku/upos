\appendix
%% \section{Appendix A}
%% \label{app:lm}

%% \begin{table}[h]
%% %        \tiny  
%%   \caption{Summary of language model training and test corpora
%%   statistics for each language in the test set.} 
%%   \begin{tabular}{@{ }l@{ }|@{ }l@{ }|@{ }c@{ }|@{ }c@{ }|@{ }c@{ }|c@{ }|@{ }c@{ }|@{ }c@{ }|@{ }c@{ }|}
%%   \hline
%%     & & \multicolumn{3}{c|}{Language Model} & \multicolumn{4}{c|}{Test set}\\    \hline
%%     & Language & Source & \specialcell{Sentence\\Count} & \specialcell{Word\\Count} & \specialcell{Sentence\\Count} & \specialcell{Word\\Count} & \specialcell{Perplexity\\(ppl)} & \specialcell{Unknown\\Word} \\ \cline{1-9}
%%     \multirow{1}{*}{\begin{sideways}\textbf{WSJ}\end{sideways}} 
%%     &English & News & 5,187,874 & 126,170,376 & 49,208 & 1,173,766 & 79.926 & 0.012\\
%%     & & & & && & &\\\hline
%%     \multirow{8}{*}{\begin{sideways}\textbf{MULTEXT-East}\end{sideways}}
%%     &Bulgarian& Wikipedia &1,596,399 & 32,511,616  & 6,682 & 101,173 & 655.202 & .0565\\
%%     &Czech & Wikipedia &3,059,678 & 59,698,049 & 6,752 & 100,368 & 1,069.67 & .0299\\
%%     &English & News & 5,187,874 & 126,170,376 & 6,737 & 118,424 & 265.246 & .0288\\
%%     &Estonian & Wikipedia &833,677 & 14,513,571 & 6,478 & 94,898 & 871.765 & .0654\\
%%     &Hungarian & Wikipedia &3,250,267& 66,069,788 & 6,768 & 98,426 & 742.676 & .0449\\
%%     &Romanian & Wikipedia &3,250,267&66,069,788  & 6,520 & 118,328 & 666.855 & .1074\\
%%     &Slovene & Wikipedia & 899,329&18,969,846 & 6,689 & 112,278 & 658.711 & .0389\\
%%     &Serbian & Wikipedia & 782,278 & 17,129,679 & 6,677 & 108,809 & 804.962 & .0580\\
%%     \hline % Conll06 data
%%     \multirow{10}{*}{\begin{sideways}\textbf{CoNLL-X Shared Task}\end{sideways}}
%%     &Bulgarian& Wikipedia &1,596,399 & 32,511,616  & 12,823 & 190,217 & 538.972 & .0430\\
%%     &Czech & Wikipedia &3,059,678 & 59,698,049 & 72,703 & 1,249,408 & 1,233.95 &.0250\\
%%     &Danish & Wikipedia &1,672,003 & 35,863,945 & 5,190 & 94,386 & 351.24 & .0393\\
%%     &Dutch & Wikipedia &8,266,922 & 159,978,524 & 13,349 & 195,069 & 390.818 & .0476\\
%%     &German & Wikipedia &22,454,543&437,777,863 & 39,216 & 699,610 & 680.036 & .0487\\
%%     &Portuguese & Wikipedia & 5,706,037 & 150,099,154 & 9071 & 206,678 & 378.656 & .0861\\
%%     &Slovene & Wikipedia & 899,329 & 18,969,846 & 1,534 & 28,750 & 663.053 & .0414\\
%%     &Spanish & Wikipedia &11,534,351 & 332,311,650& 3,306 & 89,334 & 274.418 & .0424\\
%%     &Swedish & Wikipedia &1,953,794 & 32,004,538& 11,042 & 191,467 & 1,233.95 & .0250\\
%%     &Turkish & Web &39,595,781 & 491,195,991& 4,997 & 47,605 & 868.829 & .0508\\
%%     \hline
%%   \end{tabular}
%%   \label{tab:lmstatistics}
%% \end{table}

%% \noindent Table~\ref{tab:lmstatistics} presents statistics related to the
%% language model training and testing corpora.  For all languages except
%% Serbian, English and Turkish, we trained the language models using the
%% corresponding Wikipedia dump files\footnote{Latest Wikipedia dump
%% files are freely available at \url{http://dumps.wikimedia.org/} and
%% the text in the dump files can be extracted using WP2TXT
%% (\url{http://wp2txt.rubyforge.org/})}[Should we talk about
%% tokenizer?].

%% Serbian shares common basis with Croatian and Bosnian therefore we
%% trained 3 different language models using Wikipedia dump files of
%% Serbian together with these two languages and measured the
%% perplexities on Serbian test corpus.  We chose the Croatian language
%% model since it achieved the lowest perplexity score and unknown word
%% ratio on Serbian test corpus.

%% To train statistical language model of English, we used Wall Street
%% Journal data (1987-1994) extracted from CSR-III Text \cite{csr3text}
%% (we excluded the test corpus) and for the Turkish language modeling
%% we used the web corpus that was collected from Turkish news and blog
%% sites \cite{sak2008turkish}.  

%% We set the unknown word threshold to 2 for all languages except
%% English.  English has relatively low unknown word ratio therefore we
%% set the threshold to 20 instead of 2. [double check for Multext-East.]

\section{Appendix B}
\label{app:dist1M}
\begin{table}[ht] \centering
\caption{Supervised baseline scores with different 
distance metrics on 1M word WSJ Penn Treebank corpus.}
\begin{tabular}{|l|c|}
\hline
Metric & Accuracy(\%) \\
\hline
%% K=30 1M WSJ
KL2 & - \\
Manhattan & .7353\\ %0.735381668919
Jensen & .7317 \\ %0.731718247078
Cosine & .7240 \\ %0.724018245545
Maximum & ?? \\
Euclid & .6109 \\ %0.610962491672
%% lg2-Maximum & ? \\
%% lg2-Cosine & ? \\
%% lg2-Euclid & ? \\
%% lg2-Manhattan & ? \\
\hline
\end{tabular}
\label{tab:distscores1M}
\end{table}
