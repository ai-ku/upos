\appendix
\section{Appendix A}
\label{app:lm}

\begin{table}[h]
%        \tiny   
  \begin{tabular}{l|l|c|c|c|c|c|c|c|}
    \cline{2-9}
    & & \multicolumn{3}{c|}{Language Model} & \multicolumn{4}{c|}{Test set}\\    \cline{2-9}
    & Language & Source & \specialcell{Sentence\\Count} & \specialcell{Word\\Count} & \specialcell{Sentence\\Count} & \specialcell{Word\\Count} & \specialcell{Perplexity\\(ppl)} & \specialcell{Unknown\\Word} \\ \cline{1-9}
    \multirow{1}{*}{\begin{sideways}\textbf{WSJ}\end{sideways}} 
    &English & News & 5,187,874 & 126,170,376 & 49,208 & 1,173,766 & ?? & ??\\
    & & & & && & &\\\hline
    \multirow{8}{*}{\begin{sideways}\textbf{MULTEXT-East}\end{sideways}}
    &Bulgarian& Wikipedia &1,596,399 & 32,511,616  & 6,682 & 101,173 & 655.202 & .0565\\
    &Czech & Wikipedia &3,059,678 & 59,698,049 & 6,752 & 100,368 & 1,069.67 & .0299\\
    &English & News & 5,187,874 & 126,170,376 & 6,737 & 118,424 & 265.246 & .0288\\
    &Estonian & Wikipedia &833,677 & 14,513,571 & 6,478 & 94,898 & 871.765 & .0654\\
    &Hungarian & Wikipedia &3,250,267& 66,069,788 & 6,768 & 98,426 & 742.676 & .0449\\
    &Romanian & Wikipedia &3,250,267&66,069,788  & 6,520 & 118,328 & 666.855 & .1074\\
    &Slovene & Wikipedia & 899,329&18,969,846 & 6,689 & 112,278 & 658.711 & .0389\\
    &Serbian & Wikipedia & 1,350,410 & 34,081,357 & 6,677 & 108,809 & 1,131.89 & .0989\\
    \hline % Conll06 data
    \multirow{10}{*}{\begin{sideways}\textbf{CoNLL06 Shared Task}\end{sideways}}
    &Bulgarian& Wikipedia &1,596,399 & 32,511,616  & 12,823 & 190,217 & 538.972 & .0043\\
    &Czech & Wikipedia &3,059,678 & 59,698,049 & 72,703 & 1,249,408 & 1,233.95 &.0250\\
    &Danish & Wikipedia &1,672,003 & 35,863,945 & 5,190 & 94,386 & 351.24 & .0393\\
    &Dutch & Wikipedia &8,266,922 & 159,978,524 & 13,349 & 195,069 & 390.818 & .0476\\
    &German & Wikipedia &22,454,543&437,777,863 & 39,216 & 699,610 & 680.036 & .0487\\
    &Portuguese & Wikipedia & 5,706,037 & 150,099,154 & 9071 & 206,678 & 378.656 & .0861\\
    &Slovene & Wikipedia & 899,329 & 18,969,846 & 1,534 & 28,750 & 663.053 & .0414\\
    &Spanish & Wikipedia &11,534,351 & 332,311,650& 3,306 & 89,334 & 274.418 & .0424\\
    &Swedish & Wikipedia &1,953,794 & 32,004,538& 11,042 & 191,467 & 1,233.95 & .0250\\
    &Turkish & Web &39,595,781 & 491,195,991& 4,997 & 47,605 & 868.829 & .0508\\
    \hline
  \end{tabular}
  \caption{Summary of language model training and test corpora
  realted information for each language in the test set.}
  \label{tab:lmstatistics}
\end{table}

\noindent Table~\ref{tab:lmstatistics} presents statistics related to the
language model training and test corpora.  For all languages except
English and Turkish, we train the language models using the
corresponding wikipedia dump files\footnote{Latest Wikipedia dump
files are freely available at \url{http://dumps.wikimedia.org/} and
the text in the dumpfiles can be extracted using WP2TXT
(\url{http://wp2txt.rubyforge.org/})}[Should we talk about tokenizer].

To train statistical language model of English, we use Wall Street
Journal data (1987-1994) extracted from CSR-III Text \cite{csr3text}
(we excluded the test corpus) and for the Turkish language modelling
we use the web corpus that is collected from Turkish news and blog
sites\cite{sak2008turkish}.  We set the unknown word threshold to 2
for all languages except English.  English has relatively low unknown
word therefore we set the threshold to 20 instead of 2.[double check
for multext east.]

\section{Appendix B}
\label{app:tags}
Test2 Appendix~\ref{app:tags} This might require lots of spaces since
some languages has 80 tags.
