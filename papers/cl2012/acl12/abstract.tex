\begin{abstract}
We introduce a paradigmatic representation of word context and
demonstrate its utility in learning syntactic categories.  Unlike the
typical syntagmatic representations of word context which consist of
properties of neighboring words, our paradigmatic representation
consists of substitute vectors: possible substitutes of the target
word and their probabilities.  When word contexts are clustered based
on their substitute vectors they reveal a grouping that largely match
the traditional part of speech boundaries with a many-to-one accuracy
of \collapseResult\% on a 45-tag 24K word test corpus.
\end{abstract}
